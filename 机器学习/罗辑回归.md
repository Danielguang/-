##### 逻辑回归

- 输出是概率
- 激活函数输出非线性变化

##### 实际案例

![image-20201127162734525](/Users/zhaoguangyu/Daniel/学习笔记/机器学习/img/image-20201127162734525.png)

##### 操作步骤

1. 加载二分类数据集
2. 定义模型结构： 带有激活函数的单个神经元
3. 训练模型并预测

##### 加载二分类数据集

- 使用预先准备好的脚本生成二分类数据集
- 可视化二分类数据集

``` javascript
  model.add(tf.layers.dense({
    units:1,
    inputShape:[2],
    activation:'sigmoid'
  }))
// dense 是指全链接层
// This layer implements the operation: output = activation(dot(input, kernel) + bias)

//activation（激活函数） is the element-wise activation function passed as the activation argument.

// kernel（权重） is a weights matrix created by the layer.

// bias（偏置） is a bias vector created by the layer (only applicable if useBias is true).


// 激活函数 sigmoid


```



![image-20201130104229186](/Users/zhaoguangyu/Daniel/学习笔记/机器学习/img/image-20201130104229186.png)

#### 损失函数（对数损失）logLoss

![image-20201127165210658](/Users/zhaoguangyu/Daniel/学习笔记/机器学习/img/image-20201127165210658.png)

- 用于输出0，1 之间分类的函数
- 当损失函数达到一的时候，无限大
- 当损失函数无限接近于0 

``` JavaScript
function logLoss(p, label){
  if(label === 1){
    return -log(p)
  }else {
    return -log(1-p)
  }
}
```

